---
title: Car Insurance Claims Classification Report
authors:
    name: Hamed Vaheb
    email: hamed.vaheb.001@student.uni.lu
abstract: 
  This report describes the project of analysis and prediction of the car insurance claims dataset. The dataset includes historical data of the policyholders (e.g., age, gender, vehicle details , etc.), among which the variable of interest is the outcome of insurance, indicating whether a customer's claim is approved or not. The `aiinsurance` R package \cite{package} is developed to make this work reproducible, accessible, and equipped with advanced features, e.g., a pipeline that performs the main steps of this work in a single command, and an interactive app that displays the performance of the models. Using package's functions, two machine learning models, i.e., logistic regression and random forest are implemented to classify the outcomes based on solely the historical data. The results indicate promising prediction power with various evaluation metrics (e.g., accuracy, precision, recall, etc.) of over 80 percent. In addition to classification, informative insights from the dataset and models have been drawn, e.g., by dint of the random forest model, the variables of the dataset that perform more effective role in the prediction become evident.

bibliography: references.bib
biblio-style: unsrt
output: rticles::arxiv_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(aiinsurance)
library(dplyr)
library(janitor)
library(visdat)
library(ggplot2)
library(imbalance)
library(readr)
library(caret) #for dummyVar function
library(Metrics)
library(randomForest)
library(tidyverse)
library(fontawesome)
```


# Introduction

\begin{wrapfigure}{l}{0.35\textwidth}
\includegraphics[width=0.9\linewidth]{./figures/aiactuary.png}
\end{wrapfigure}

Rapid advances in artificial intelligence (AI) and machine learning are creating products and services with
the potential not only to change the environment in which actuaries operate but also to provide new opportunities within actuarial science \cite{aiinins}.

The use of statistical learning models has been a common practice in actuarial science since the 1980s. 
It was not long after since the field adopted classical models, such as linear models and generalized linear models (GLMs).
While actuaries use GLMs frequently in practice, it was in the past few years that the use of AI and machine learning, and hence more modern models garnered significant attention in the field \cite{rev1}.

The goal of this work is to predict status of policyholders' claims. 
The status lies at the "outcome" column of the car insruance dataset, indicating whether a customer has claimed his loan or not.

A classical linear model and a modern nonlinear model is used and compared.
The former model is logistic regression, which is an example of GLMs, accommodated to classification setting, i.e., for predicting discrete classes, in this work's case, status of claims.
The latter model is a nonlinear tree-based model.

The remainder of this work is organized as the following:
In section \ref{sec:concepts}, main concepts included in the work are explained. In \ref{subsec:claim}, the concept of car insurance is introduced followed by an elaboration on claims and how they interact among an insurer and a policyholder. Subsequently, the two machine learning models, logistic regression \ref{subsec:model-logit}, and random forest \ref{subsec:model-rf} are briefly explained.
As a contribution of this work, the `aiinsurance` package \cite{package}, introduced in \ref{subsec:package}, is developed, which automates many of the classification tasks, uses advanced features, e.g., runs a pipeline that performs the main steps of this work in a single command, and it provides an interactive shiny app to display the performance of the models.


\newpage

# Preliminary Concepts \label{sec:concepts}
## Car Insurance Claims \label{subsec:claim}

\begin{wrapfigure}{l}{0.25\textwidth}
\includegraphics[width=0.9\linewidth]{./figures/carinsurance.png}
\end{wrapfigure}

Car insurance is a type of insurance policy that financially protects drivers in the event of an accident or theft. There are several types of car insurance coverage, including liability insurance, collision insurance, comprehensive insurance, and personal injury protection. 

An insurance claim is a formal request by a policyholder to an insurance company for coverage or compensation for a covered loss or policy event, in this work's case, a car accident. The insurance company either accepts or rejects the claim. If it is approved, the insurance company will issue payment to the insured or an approved interested party on behalf of the insured.

Predicting the outcome of claims can be utilized to better understand the customer strata and incorporate the findings throughout the insurance policy enrollment (including the underwriting and approval or rejection stages), triage claims and automate where possible, gradually obviating the need for human interaction, and optimize the entire insurance policy enrollment process flow \cite{claim}.


## Model: Logistic Regression \label{subsec:model-logit}

\begin{wrapfigure}{l}{0.25\textwidth}
\includegraphics[width=0.7\linewidth]{./figures/logit-model.png}
\end{wrapfigure}

Logistic regression (logit), which is type of GLM, uses the logistic function to model the probability of the binary outcome by creating a model that takes in the input variable (e.g., client's information) and produces a probability that a  "outcome" (the variable we aim to predict) is 1. The "outcome" in this work is whether a customer's claim is approved or not.
The logistic function is defined as the following:

$$\frac{1}{1 + e^{-x}}$$

This probability can then be used to make a prediction about the outcome. For instance, if the probability that the client's claim will be approved is greater than a certain threshold (e.g., 0.5), we predict that the claim will be approved.
In another words, the goal of logit is to find the best set of coefficients for a set of independent variables that maximizes the likelihood (measuring how well parameters of a model fit the data) of the observed data.



## Model: Random Forest \label{subsec:model-rf}

\begin{wrapfigure}{l}{0.35\textwidth}
\includegraphics[width=0.9\linewidth]{./figures/rf-model.png}
\end{wrapfigure}

An ensemble learning model is a model that is constructed from multiple models, to obtain combined results, expected to be improved compared to any of the constituent models. 
The random forest is an ensemble model built from decision trees, i.e., flowchart-like tree structures, wherein each internal node represents a "test" on a variable (e.g., vehicle type), each branch represents the outcome of the test, and each leaf node represents a class label (e.g., 1 for claim approval and 0 for claim rejection). The intuition behind a decision tree is to recursively split the data into subsets based on the values of the input variables, such that the subsets are as "pure" as possible in terms of their class labels. The less pure a subset is, the more the data belongs to the same class, and the more pure it is, the more data is evenly split among all classes. The goal is to create a tree that can accurately classify new examples by traversing the tree from the root to a leaf node, making decisions at each internal node based on the values of the input variables.

As a single random tree might not be able to capture the proper inherent complexity of a data, and may either overfit (become too complex and remembers data rather than learning from it) or underfit (become too simple and hence unable to learn the inherent complicated patterns in the data). By training multiple decision trees and combining their predictions by taking a majority vote, a random forest is able to capture a more robust and accurate representation of the data. The randomness in the random forest comes from randomly selecting subsets of the data to train each decision tree, and randomly selecting subsets of input variables to consider at each split point in the decision tree. This helps to decorrelate the trees and make the model more robust to overfitting.








# Implementation \label{sec:impl}

## `aiinsurance` Package \label{subsec:package} 


\begin{wrapfigure}{l}{0.15\textwidth}
\includegraphics[width=0.7\linewidth]{"./figures/logo.png"}
\caption*{ \href{Icon Source: }{https://aiinsurance.io/}}
\end{wrapfigure}

The `aiinsurance` R package \cite{package} is developed to make this work reproducible, accessible, and equipped with advanced features.

Instructions on how to install and use the package is provided in the README file of package's [Github repository](https://github.com/berserkhmdvhb/aiinsurance) `r fa(name = "github")`


e.g., a pipeline that performs the main steps of this work in a single command, and an interactive app that displays the performance of the models. Using package's functions







## Exploratory Data Analysis (EDA) \label{sec:data}

\tiny
```{r, echo=FALSE}
data(car_insurance_data)
df <- janitor::clean_names(car_insurance_data)
df |> dplyr::glimpse()
```
\normalsize


List of categorical columns including characters:

1] "List of categorical columns containing characters: "
[1] "age"                "gender"            
[3] "race"               "driving_experience"
[5] "education"          "income"            
[7] "vehicle_year"       "vehicle_type"      
[1] "List of categorical columns containing numbers: "
[1] "vehicle_ownership" "married"          
[3] "children"          "postal_code"      
[5] "outcome"    




## Classification Models \label{subsec:models}


# Results and Discussion \label{sec:results}


# Conclusion

\newpage


# Headings: first level \label{sec:headings}


LaTeX command can be used to reference other section. See Section \ref{sec:headings}.
However, you can also use **bookdown** extensions mechanism for this.



# Examples of citations, figures, tables, references \label{sec:others}


The documentation for \verb+natbib+ may be found at

You can use custom blocks with LaTeX support from **rmarkdown** to create environment.

::: {.center latex=true}
  <http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}>
:::

Of note is the command \verb+\citet+, which produces citations
appropriate for use in inline text.  

You can insert LaTeX environment directly too.

\begin{verbatim}
   investigated\dots
\end{verbatim}

produces

\begin{quote}
  Hasselmo, et al.\ (1995) investigated\dots
\end{quote}

\begin{center}
  \url{https://www.ctan.org/pkg/booktabs}
\end{center}


## Figures

You can insert figure using LaTeX directly. 

See Figure \ref{fig:fig1}. Here is how you add footnotes. [^Sample of the first footnote.]

\begin{figure}
  \centering
  \fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \caption{Sample figure caption.}
  \label{fig:fig1}
\end{figure}

But you can also do that using R.

```{r fig2, fig.cap = "Another sample figure"}
plot(mtcars$mpg)
```

You can use **bookdown** to allow references for Tables and Figures.


## Tables

Below we can see how to use tables. 

See awesome Table~\ref{tab:table} which is written directly in LaTeX in source Rmd file.

\begin{table}
 \caption{Sample table title}
  \centering
  \begin{tabular}{lll}
    \toprule
    \multicolumn{2}{c}{Part}                   \\
    \cmidrule(r){1-2}
    Name     & Description     & Size ($\mu$m) \\
    \midrule
    Dendrite & Input terminal  & $\sim$100     \\
    Axon     & Output terminal & $\sim$10      \\
    Soma     & Cell body       & up to $10^6$  \\
    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}

You can also use R code for that.

```{r}
knitr::kable(head(mtcars), caption = "Head of mtcars table")
```


## Lists

- Item 1
- Item 2 
- Item 3
