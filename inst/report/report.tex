\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{lmodern}        % https://github.com/rstudio/rticles/issues/343
\usepackage[pagebackref=false,colorlinks,urlcolor=red,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{wrapfig}

\title{Car Insurance Claims Classification Report}

\author{
    Hamed Vaheb\\
  \texttt{\href{mailto:hamed.vaheb.001@student.uni.lu}{\nolinkurl{hamed.vaheb.001@student.uni.lu}}}% \\
  }

% Pandoc syntax highlighting
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% From pandoc table feature
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}


\begin{document}
\maketitle


\begin{abstract}
This report describes the project of analysis and prediction of the car
insurance claims dataset. The dataset includes historical data of the
policyholders (e.g., age, gender, vehicle details , etc.), among which
the variable of interest is the outcome of insurance, indicating whether
a customer's claim is approved or not. The \texttt{aiinsurance} R
package \cite{package} is developed to make this work reproducible,
accessible, and equipped with advanced features, e.g., a pipeline that
performs the main steps of this work in a single command, and an
interactive app that displays the performance of the models. Using
package's functions, two machine learning models, i.e., logistic
regression and random forest are implemented to classify the outcomes
based on solely the historical data. The results indicate promising
prediction power with various evaluation metrics (e.g., accuracy,
precision, recall, etc.) of over 80 percent. In addition to
classification, informative insights from the dataset and models have
been drawn, e.g., by dint of the random forest model, the variables of
the dataset that perform more effective role in the prediction become
evident.
\end{abstract}


\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\begin{wrapfigure}{l}{0.35\textwidth}
\includegraphics[width=0.9\linewidth]{./figures/aiactuary.png}
\end{wrapfigure}

Rapid advances in artificial intelligence (AI) and machine learning are
creating products and services with the potential not only to change the
environment in which actuaries operate but also to provide new
opportunities within actuarial science \cite{aiinins}.

The use of statistical learning models has been a common practice in
actuarial science since the 1980s. It was not long after since the field
adopted classical models, such as linear models and generalized linear
models (GLMs). While actuaries use GLMs frequently in practice, it was
in the past few years that the use of AI and machine learning, and hence
more modern models garnered significant attention in the field
\cite{rev1}.

The goal of this work is to predict status of policyholders' claims. The
status lies at the ``outcome'' column of the car insruance dataset,
indicating whether a customer has claimed his loan or not.

A classical linear model and a modern nonlinear model is used and
compared. The former model is logistic regression, which is an example
of GLMs, accommodated to classification setting, i.e., for predicting
discrete classes, in this work's case, status of claims. The latter
model is a nonlinear tree-based model.

The remainder of this work is organized as the following: In section
\ref{sec:concepts}, main concepts included in the work are explained. In
\ref{subsec:claim}, the concept of car insurance is introduced followed
by an elaboration on claims and how they interact among an insurer and a
policyholder. Subsequently, the two machine learning models, logistic
regression \ref{subsec:model-logit}, and random forest
\ref{subsec:model-rf} are briefly explained. As a contribution of this
work, the \texttt{aiinsurance} package \cite{package}, introduced in
\ref{subsec:package}, is developed, which automates many of the
classification tasks, uses advanced features, e.g., runs a pipeline that
performs the main steps of this work in a single command, and it
provides an interactive shiny app to display the performance of the
models.

\newpage

\hypertarget{preliminary-concepts}{%
\section{\texorpdfstring{Preliminary Concepts
\label{sec:concepts}}{Preliminary Concepts }}\label{preliminary-concepts}}

\hypertarget{car-insurance-claims}{%
\subsection{\texorpdfstring{Car Insurance Claims
\label{subsec:claim}}{Car Insurance Claims }}\label{car-insurance-claims}}

\begin{wrapfigure}{l}{0.25\textwidth}
\includegraphics[width=0.9\linewidth]{./figures/carinsurance.png}
\end{wrapfigure}

Car insurance is a type of insurance policy that financially protects
drivers in the event of an accident or theft. There are several types of
car insurance coverage, including liability insurance, collision
insurance, comprehensive insurance, and personal injury protection.

An insurance claim is a formal request by a policyholder to an insurance
company for coverage or compensation for a covered loss or policy event,
in this work's case, a car accident. The insurance company either
accepts or rejects the claim. If it is approved, the insurance company
will issue payment to the insured or an approved interested party on
behalf of the insured.

Predicting the outcome of claims can be utilized to better understand
the customer strata and incorporate the findings throughout the
insurance policy enrollment (including the underwriting and approval or
rejection stages), triage claims and automate where possible, gradually
obviating the need for human interaction, and optimize the entire
insurance policy enrollment process flow \cite{claim}.

\hypertarget{model-logistic-regression}{%
\subsection{\texorpdfstring{Model: Logistic Regression
\label{subsec:model-logit}}{Model: Logistic Regression }}\label{model-logistic-regression}}

\begin{wrapfigure}{l}{0.25\textwidth}
\includegraphics[width=0.7\linewidth]{./figures/logit-model.png}
\end{wrapfigure}

Logistic regression (logit), which is type of GLM, uses the logistic
function to model the probability of the binary outcome by creating a
model that takes in the input variable (e.g., client's information) and
produces a probability that a ``outcome'' (the variable we aim to
predict) is 1. The ``outcome'' in this work is whether a customer's
claim is approved or not. The logistic function is defined as the
following:

\[\frac{1}{1 + e^{-x}}\]

This probability can then be used to make a prediction about the
outcome. For instance, if the probability that the client's claim will
be approved is greater than a certain threshold (e.g., 0.5), we predict
that the claim will be approved. In another words, the goal of logit is
to find the best set of coefficients for a set of independent variables
that maximizes the likelihood (measuring how well parameters of a model
fit the data) of the observed data.

\hypertarget{model-random-forest}{%
\subsection{\texorpdfstring{Model: Random Forest
\label{subsec:model-rf}}{Model: Random Forest }}\label{model-random-forest}}

\begin{wrapfigure}{l}{0.35\textwidth}
\includegraphics[width=0.9\linewidth]{./figures/rf-model.png}
\end{wrapfigure}

An ensemble learning model is a model that is constructed from multiple
models, to obtain combined results, expected to be improved compared to
any of the constituent models. The random forest is an ensemble model
built from decision trees, i.e., flowchart-like tree structures, wherein
each internal node represents a ``test'' on a variable (e.g., vehicle
type), each branch represents the outcome of the test, and each leaf
node represents a class label (e.g., 1 for claim approval and 0 for
claim rejection). The intuition behind a decision tree is to recursively
split the data into subsets based on the values of the input variables,
such that the subsets are as ``pure'' as possible in terms of their
class labels. The less pure a subset is, the more the data belongs to
the same class, and the more pure it is, the more data is evenly split
among all classes. The goal is to create a tree that can accurately
classify new examples by traversing the tree from the root to a leaf
node, making decisions at each internal node based on the values of the
input variables.

As a single random tree might not be able to capture the proper inherent
complexity of a data, and may either overfit (become too complex and
remembers data rather than learning from it) or underfit (become too
simple and hence unable to learn the inherent complicated patterns in
the data). By training multiple decision trees and combining their
predictions by taking a majority vote, a random forest is able to
capture a more robust and accurate representation of the data. The
randomness in the random forest comes from randomly selecting subsets of
the data to train each decision tree, and randomly selecting subsets of
input variables to consider at each split point in the decision tree.
This helps to decorrelate the trees and make the model more robust to
overfitting.

\hypertarget{implementation}{%
\section{\texorpdfstring{Implementation
\label{sec:impl}}{Implementation }}\label{implementation}}

\hypertarget{aiinsurance-package}{%
\subsection{\texorpdfstring{\texttt{aiinsurance} Package
\label{subsec:package}}{aiinsurance Package }}\label{aiinsurance-package}}

\includegraphics[width=0.05\linewidth]{../figures/logo} README file in
the main page of package's
\href{https://github.com/berserkhmdvhb/aiinsurance}{Github repository}
\includegraphics[width=0.97em,height=1em]{report_files/figure-latex/fa-icon-9e25601f72c0b4fff1c079a486ca8bba.pdf}

\hypertarget{exploratory-data-analysis-eda}{%
\subsection{\texorpdfstring{Exploratory Data Analysis (EDA)
\label{sec:data}}{Exploratory Data Analysis (EDA) }}\label{exploratory-data-analysis-eda}}

\begin{verbatim}
## Rows: 10,000
## Columns: 19
## $ id                  <int> 569520, 750365, 199901, 478866, 731664, 877557, 93~
## $ age                 <chr> "65+", "16-25", "16-25", "16-25", "26-39", "40-64"~
## $ gender              <chr> "female", "male", "female", "male", "male", "femal~
## $ race                <chr> "majority", "majority", "majority", "majority", "m~
## $ driving_experience  <chr> "0-9y", "0-9y", "0-9y", "0-9y", "10-19y", "20-29y"~
## $ education           <chr> "high school", "none", "high school", "university"~
## $ income              <chr> "upper class", "poverty", "working class", "workin~
## $ credit_score        <dbl> 0.6290273, 0.3577571, 0.4931458, 0.2060129, 0.3883~
## $ vehicle_ownership   <int> 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,~
## $ vehicle_year        <chr> "after 2015", "before 2015", "before 2015", "befor~
## $ married             <int> 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,~
## $ children            <int> 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,~
## $ postal_code         <int> 10238, 10238, 10238, 32765, 32765, 10238, 10238, 1~
## $ annual_mileage      <int> 12000, 16000, 11000, 11000, 12000, 13000, 13000, 1~
## $ vehicle_type        <chr> "sedan", "sedan", "sedan", "sedan", "sedan", "seda~
## $ speeding_violations <int> 0, 0, 0, 0, 2, 3, 7, 0, 0, 0, 6, 4, 4, 0, 0, 0, 10~
## $ duis                <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 2,~
## $ past_accidents      <int> 0, 0, 0, 0, 1, 3, 3, 0, 0, 0, 7, 0, 2, 0, 1, 0, 1,~
## $ outcome             <int> 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,~
\end{verbatim}

List of categorical columns including characters:

1{]} ``List of categorical columns containing characters:'' {[}1{]}
``age'' ``gender''\\
{[}3{]} ``race'' ``driving\_experience'' {[}5{]} ``education''
``income''\\
{[}7{]} ``vehicle\_year'' ``vehicle\_type''\\
{[}1{]} ``List of categorical columns containing numbers:'' {[}1{]}
``vehicle\_ownership'' ``married''\\
{[}3{]} ``children'' ``postal\_code''\\
{[}5{]} ``outcome''

\hypertarget{classification-models}{%
\subsection{\texorpdfstring{Classification Models
\label{subsec:models}}{Classification Models }}\label{classification-models}}

\hypertarget{results-and-discussion}{%
\section{\texorpdfstring{Results and Discussion
\label{sec:impl}}{Results and Discussion }}\label{results-and-discussion}}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

\newpage

\hypertarget{headings-first-level}{%
\section{Headings: first level}\label{headings-first-level}}

\label{sec:headings}

LaTeX command can be used to reference other section. See Section
\ref{sec:headings}. However, you can also use \textbf{bookdown}
extensions mechanism for this.

\hypertarget{headings-second-level}{%
\subsection{Headings: second level}\label{headings-second-level}}

You can use equation in blocks

\[
\xi _{ij}(t)=P(x_{t}=i,x_{t+1}=j|y,v,w;\theta)= {\frac {\alpha _{i}(t)a^{w_t}_{ij}\beta _{j}(t+1)b^{v_{t+1}}_{j}(y_{t+1})}{\sum _{i=1}^{N} \sum _{j=1}^{N} \alpha _{i}(t)a^{w_t}_{ij}\beta _{j}(t+1)b^{v_{t+1}}_{j}(y_{t+1})}}
\]

But also inline i.e \(z=x+y\)

\hypertarget{headings-third-level}{%
\subsubsection{Headings: third level}\label{headings-third-level}}

Another paragraph.

\hypertarget{examples-of-citations-figures-tables-references}{%
\section{Examples of citations, figures, tables,
references}\label{examples-of-citations-figures-tables-references}}

\label{sec:others}

You can insert references. Here is some text (\textbf{kour2014real?};
\textbf{kour2014fast?}) and see (\textbf{hadash2018estimate?}).

The documentation for \verb+natbib+ may be found at

You can use custom blocks with LaTeX support from \textbf{rmarkdown} to
create environment.

\begin{center}
\url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf\%7D}

\end{center}

Of note is the command \verb+\citet+, which produces citations
appropriate for use in inline text.

You can insert LaTeX environment directly too.

\begin{verbatim}
   \citet{hasselmo} investigated\dots
\end{verbatim}

produces

\begin{quote}
  Hasselmo, et al.\ (1995) investigated\dots
\end{quote}

\begin{center}
  \url{https://www.ctan.org/pkg/booktabs}
\end{center}

\hypertarget{figures}{%
\subsection{Figures}\label{figures}}

You can insert figure using LaTeX directly.

See Figure \ref{fig:fig1}. Here is how you add footnotes. {[}\^{}Sample
of the first footnote.{]}

\begin{figure}
  \centering
  \fbox{\rule[-.5cm]{4cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \caption{Sample figure caption.}
  \label{fig:fig1}
\end{figure}

But you can also do that using R.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(mtcars}\SpecialCharTok{$}\NormalTok{mpg)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{report_files/figure-latex/fig2-1.pdf}
\caption{Another sample figure}
\end{figure}

You can use \textbf{bookdown} to allow references for Tables and
Figures.

\hypertarget{tables}{%
\subsection{Tables}\label{tables}}

Below we can see how to use tables.

See awesome Table\textasciitilde{}\ref{tab:table} which is written
directly in LaTeX in source Rmd file.

\begin{table}
 \caption{Sample table title}
  \centering
  \begin{tabular}{lll}
    \toprule
    \multicolumn{2}{c}{Part}                   \\
    \cmidrule(r){1-2}
    Name     & Description     & Size ($\mu$m) \\
    \midrule
    Dendrite & Input terminal  & $\sim$100     \\
    Axon     & Output terminal & $\sim$10      \\
    Soma     & Cell body       & up to $10^6$  \\
    \bottomrule
  \end{tabular}
  \label{tab:table}
\end{table}

You can also use R code for that.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}\FunctionTok{head}\NormalTok{(mtcars), }\AttributeTok{caption =} \StringTok{"Head of mtcars table"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrrrrrrrr@{}}
\caption{Head of mtcars table}\tabularnewline
\toprule
& mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb \\
\midrule
\endfirsthead
\toprule
& mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb \\
\midrule
\endhead
Mazda RX4 & 21.0 & 6 & 160 & 110 & 3.90 & 2.620 & 16.46 & 0 & 1 & 4 &
4 \\
Mazda RX4 Wag & 21.0 & 6 & 160 & 110 & 3.90 & 2.875 & 17.02 & 0 & 1 & 4
& 4 \\
Datsun 710 & 22.8 & 4 & 108 & 93 & 3.85 & 2.320 & 18.61 & 1 & 1 & 4 &
1 \\
Hornet 4 Drive & 21.4 & 6 & 258 & 110 & 3.08 & 3.215 & 19.44 & 1 & 0 & 3
& 1 \\
Hornet Sportabout & 18.7 & 8 & 360 & 175 & 3.15 & 3.440 & 17.02 & 0 & 0
& 3 & 2 \\
Valiant & 18.1 & 6 & 225 & 105 & 2.76 & 3.460 & 20.22 & 1 & 0 & 3 & 1 \\
\bottomrule
\end{longtable}

\hypertarget{lists}{%
\subsection{Lists}\label{lists}}

\begin{itemize}
\tightlist
\item
  Item 1
\item
  Item 2
\item
  Item 3
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{references.bib}


\end{document}
